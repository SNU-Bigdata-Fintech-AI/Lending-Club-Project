{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b739aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\seon\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\seon\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.22.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\seon\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: xgboost in c:\\users\\seon\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.0.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\seon\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.65.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\seon\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\seon\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\seon\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.8.1)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\seon\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\seon\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\seon\\appdata\\roaming\\python\\python310\\site-packages (from tqdm) (0.4.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\seon\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy scikit-learn xgboost tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdc17fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04320ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS S3에서 데이터 load\n",
    "url = \"https://snu-bigdata-fintech-ai.s3.ap-northeast-2.amazonaws.com/data/interim/preprocessed_data_ver.2.3.(IRR%2BLOG%2BBINARY).csv\"\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8914423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 열 다 보기\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# 모든 행 다 보기\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# 열 너비 넉넉하게\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "# 열 안의 값 자르지 않게\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53ad51c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>term</th>\n",
       "      <th>installment</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>issue_d</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>fico_range_low</th>\n",
       "      <th>fico_range_high</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>mths_since_last_delinq</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>recoveries</th>\n",
       "      <th>collection_recovery_fee</th>\n",
       "      <th>last_pymnt_d</th>\n",
       "      <th>last_fico_range_high</th>\n",
       "      <th>collections_12_mths_ex_med</th>\n",
       "      <th>acc_now_delinq</th>\n",
       "      <th>tot_coll_amt</th>\n",
       "      <th>tot_cur_bal</th>\n",
       "      <th>open_acc_6m</th>\n",
       "      <th>open_act_il</th>\n",
       "      <th>open_il_12m</th>\n",
       "      <th>open_il_24m</th>\n",
       "      <th>mths_since_rcnt_il</th>\n",
       "      <th>total_bal_il</th>\n",
       "      <th>il_util</th>\n",
       "      <th>open_rv_12m</th>\n",
       "      <th>open_rv_24m</th>\n",
       "      <th>max_bal_bc</th>\n",
       "      <th>all_util</th>\n",
       "      <th>total_rev_hi_lim</th>\n",
       "      <th>inq_last_12m</th>\n",
       "      <th>acc_open_past_24mths</th>\n",
       "      <th>avg_cur_bal</th>\n",
       "      <th>bc_open_to_buy</th>\n",
       "      <th>bc_util</th>\n",
       "      <th>chargeoff_within_12_mths</th>\n",
       "      <th>delinq_amnt</th>\n",
       "      <th>mo_sin_old_il_acct</th>\n",
       "      <th>mo_sin_old_rev_tl_op</th>\n",
       "      <th>mo_sin_rcnt_rev_tl_op</th>\n",
       "      <th>mo_sin_rcnt_tl</th>\n",
       "      <th>mort_acc</th>\n",
       "      <th>mths_since_recent_bc</th>\n",
       "      <th>mths_since_recent_inq</th>\n",
       "      <th>mths_since_recent_revol_delinq</th>\n",
       "      <th>num_accts_ever_120_pd</th>\n",
       "      <th>num_actv_rev_tl</th>\n",
       "      <th>num_bc_sats</th>\n",
       "      <th>num_bc_tl</th>\n",
       "      <th>num_il_tl</th>\n",
       "      <th>num_op_rev_tl</th>\n",
       "      <th>num_rev_accts</th>\n",
       "      <th>num_rev_tl_bal_gt_0</th>\n",
       "      <th>num_sats</th>\n",
       "      <th>num_tl_120dpd_2m</th>\n",
       "      <th>num_tl_30dpd</th>\n",
       "      <th>num_tl_90g_dpd_24m</th>\n",
       "      <th>num_tl_op_past_12m</th>\n",
       "      <th>pct_tl_nvr_dlq</th>\n",
       "      <th>percent_bc_gt_75</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <th>tax_liens</th>\n",
       "      <th>tot_hi_cred_lim</th>\n",
       "      <th>total_bal_ex_mort</th>\n",
       "      <th>total_bc_limit</th>\n",
       "      <th>total_il_high_credit_limit</th>\n",
       "      <th>default</th>\n",
       "      <th>addr_state_AK</th>\n",
       "      <th>addr_state_AL</th>\n",
       "      <th>addr_state_AR</th>\n",
       "      <th>addr_state_AZ</th>\n",
       "      <th>addr_state_CA</th>\n",
       "      <th>addr_state_CO</th>\n",
       "      <th>addr_state_CT</th>\n",
       "      <th>addr_state_DC</th>\n",
       "      <th>addr_state_DE</th>\n",
       "      <th>addr_state_FL</th>\n",
       "      <th>addr_state_GA</th>\n",
       "      <th>addr_state_HI</th>\n",
       "      <th>addr_state_IA</th>\n",
       "      <th>addr_state_ID</th>\n",
       "      <th>addr_state_IL</th>\n",
       "      <th>addr_state_IN</th>\n",
       "      <th>addr_state_KS</th>\n",
       "      <th>addr_state_KY</th>\n",
       "      <th>addr_state_LA</th>\n",
       "      <th>addr_state_MA</th>\n",
       "      <th>addr_state_MD</th>\n",
       "      <th>addr_state_ME</th>\n",
       "      <th>addr_state_MI</th>\n",
       "      <th>addr_state_MN</th>\n",
       "      <th>addr_state_MO</th>\n",
       "      <th>addr_state_MS</th>\n",
       "      <th>addr_state_MT</th>\n",
       "      <th>addr_state_NC</th>\n",
       "      <th>addr_state_ND</th>\n",
       "      <th>addr_state_NE</th>\n",
       "      <th>addr_state_NH</th>\n",
       "      <th>addr_state_NJ</th>\n",
       "      <th>addr_state_NM</th>\n",
       "      <th>addr_state_NV</th>\n",
       "      <th>addr_state_NY</th>\n",
       "      <th>addr_state_OH</th>\n",
       "      <th>addr_state_OK</th>\n",
       "      <th>addr_state_OR</th>\n",
       "      <th>addr_state_PA</th>\n",
       "      <th>addr_state_RI</th>\n",
       "      <th>addr_state_SC</th>\n",
       "      <th>addr_state_SD</th>\n",
       "      <th>addr_state_TN</th>\n",
       "      <th>addr_state_TX</th>\n",
       "      <th>addr_state_UT</th>\n",
       "      <th>addr_state_VA</th>\n",
       "      <th>addr_state_VT</th>\n",
       "      <th>addr_state_WA</th>\n",
       "      <th>addr_state_WI</th>\n",
       "      <th>addr_state_WV</th>\n",
       "      <th>addr_state_WY</th>\n",
       "      <th>addr_state_nan</th>\n",
       "      <th>home_ownership_ANY</th>\n",
       "      <th>home_ownership_MORTGAGE</th>\n",
       "      <th>home_ownership_NONE</th>\n",
       "      <th>home_ownership_OTHER</th>\n",
       "      <th>home_ownership_OWN</th>\n",
       "      <th>home_ownership_RENT</th>\n",
       "      <th>home_ownership_nan</th>\n",
       "      <th>purpose_car</th>\n",
       "      <th>purpose_credit_card</th>\n",
       "      <th>purpose_debt_consolidation</th>\n",
       "      <th>purpose_educational</th>\n",
       "      <th>purpose_home_improvement</th>\n",
       "      <th>purpose_house</th>\n",
       "      <th>purpose_major_purchase</th>\n",
       "      <th>purpose_medical</th>\n",
       "      <th>purpose_moving</th>\n",
       "      <th>purpose_other</th>\n",
       "      <th>purpose_renewable_energy</th>\n",
       "      <th>purpose_small_business</th>\n",
       "      <th>purpose_vacation</th>\n",
       "      <th>purpose_wedding</th>\n",
       "      <th>purpose_nan</th>\n",
       "      <th>emp_length_missing</th>\n",
       "      <th>percent_bc_gt_75_missing</th>\n",
       "      <th>mths_since_recent_inq_missing</th>\n",
       "      <th>installment_missing</th>\n",
       "      <th>inq_last_6mths_missing</th>\n",
       "      <th>mths_since_last_delinq_missing</th>\n",
       "      <th>total_acc_missing</th>\n",
       "      <th>recoveries_missing</th>\n",
       "      <th>open_acc_missing</th>\n",
       "      <th>all_util_missing</th>\n",
       "      <th>last_fico_range_high_missing</th>\n",
       "      <th>open_act_il_missing</th>\n",
       "      <th>total_bal_il_missing</th>\n",
       "      <th>revol_bal_missing</th>\n",
       "      <th>open_il_24m_missing</th>\n",
       "      <th>acc_now_delinq_missing</th>\n",
       "      <th>annual_inc_missing</th>\n",
       "      <th>pub_rec_missing</th>\n",
       "      <th>fico_range_low_missing</th>\n",
       "      <th>max_bal_bc_missing</th>\n",
       "      <th>delinq_2yrs_missing</th>\n",
       "      <th>open_rv_12m_missing</th>\n",
       "      <th>open_acc_6m_missing</th>\n",
       "      <th>delinq_amnt_missing</th>\n",
       "      <th>open_rv_24m_missing</th>\n",
       "      <th>mths_since_recent_revol_delinq_missing</th>\n",
       "      <th>fico_range_high_missing</th>\n",
       "      <th>funded_amnt_missing</th>\n",
       "      <th>inq_last_12m_missing</th>\n",
       "      <th>collection_recovery_fee_missing</th>\n",
       "      <th>mths_since_rcnt_il_missing</th>\n",
       "      <th>open_il_12m_missing</th>\n",
       "      <th>il_util_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6000.0</td>\n",
       "      <td>36</td>\n",
       "      <td>187.94</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.714440</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>2.269028</td>\n",
       "      <td>1</td>\n",
       "      <td>755.0</td>\n",
       "      <td>759.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.036250</td>\n",
       "      <td>14.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Apr-2020</td>\n",
       "      <td>764.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50054.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>46964.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.036250</td>\n",
       "      <td>64.0</td>\n",
       "      <td>10.003378</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.256088</td>\n",
       "      <td>9.385218</td>\n",
       "      <td>20.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>97.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.272280</td>\n",
       "      <td>10.820878</td>\n",
       "      <td>9.615872</td>\n",
       "      <td>10.942208</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23200.0</td>\n",
       "      <td>60</td>\n",
       "      <td>680.82</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.608245</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>3.575151</td>\n",
       "      <td>1</td>\n",
       "      <td>670.0</td>\n",
       "      <td>674.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.735660</td>\n",
       "      <td>55.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>5260.00</td>\n",
       "      <td>946.800</td>\n",
       "      <td>Dec-2016</td>\n",
       "      <td>639.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>606327.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>277552.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.455105</td>\n",
       "      <td>85.0</td>\n",
       "      <td>10.317450</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.137175</td>\n",
       "      <td>8.702012</td>\n",
       "      <td>70.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>94.8</td>\n",
       "      <td>37.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.386134</td>\n",
       "      <td>12.592905</td>\n",
       "      <td>9.918425</td>\n",
       "      <td>12.582679</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16000.0</td>\n",
       "      <td>36</td>\n",
       "      <td>494.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.082158</td>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>2.930660</td>\n",
       "      <td>0</td>\n",
       "      <td>820.0</td>\n",
       "      <td>824.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.264106</td>\n",
       "      <td>5.5</td>\n",
       "      <td>28.0</td>\n",
       "      <td>936.75</td>\n",
       "      <td>168.615</td>\n",
       "      <td>Aug-2019</td>\n",
       "      <td>609.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100922.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>28670.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.856320</td>\n",
       "      <td>27.0</td>\n",
       "      <td>11.157692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.689128</td>\n",
       "      <td>10.919080</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.186584</td>\n",
       "      <td>10.390594</td>\n",
       "      <td>10.987003</td>\n",
       "      <td>10.806490</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4500.0</td>\n",
       "      <td>36</td>\n",
       "      <td>146.10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.819798</td>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>2.078191</td>\n",
       "      <td>0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>704.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.828348</td>\n",
       "      <td>49.4</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Mar-2019</td>\n",
       "      <td>744.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>194586.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>2749.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.656433</td>\n",
       "      <td>37.0</td>\n",
       "      <td>9.532496</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.232755</td>\n",
       "      <td>7.814803</td>\n",
       "      <td>73.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.8</td>\n",
       "      <td>33.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.263577</td>\n",
       "      <td>9.166806</td>\n",
       "      <td>9.137877</td>\n",
       "      <td>9.390242</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>36</td>\n",
       "      <td>645.25</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.002117</td>\n",
       "      <td>2015-09-01</td>\n",
       "      <td>3.399195</td>\n",
       "      <td>0</td>\n",
       "      <td>675.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.718783</td>\n",
       "      <td>60.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Oct-2018</td>\n",
       "      <td>669.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>137528.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.229224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.941284</td>\n",
       "      <td>6.890609</td>\n",
       "      <td>91.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>77.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.137612</td>\n",
       "      <td>11.101704</td>\n",
       "      <td>9.305741</td>\n",
       "      <td>11.199461</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   funded_amnt  term  installment  emp_length  annual_inc     issue_d  \\\n",
       "0       6000.0    36       187.94         2.0   10.714440  2017-12-01   \n",
       "1      23200.0    60       680.82        10.0   11.608245  2016-07-01   \n",
       "2      16000.0    36       494.55         0.0   11.082158  2017-10-01   \n",
       "3       4500.0    36       146.10         5.0   10.819798  2017-05-01   \n",
       "4      20000.0    36       645.25        10.0   11.002117  2015-09-01   \n",
       "\n",
       "        dti  delinq_2yrs  fico_range_low  fico_range_high  inq_last_6mths  \\\n",
       "0  2.269028            1           755.0            759.0             0.0   \n",
       "1  3.575151            1           670.0            674.0             1.0   \n",
       "2  2.930660            0           820.0            824.0             0.0   \n",
       "3  2.078191            0           700.0            704.0             0.0   \n",
       "4  3.399195            0           675.0            679.0             0.0   \n",
       "\n",
       "   mths_since_last_delinq  open_acc  pub_rec  revol_bal  revol_util  \\\n",
       "0                    22.0      14.0        0   8.036250        14.0   \n",
       "1                    10.0      24.0        0   9.735660        55.9   \n",
       "2                     0.0      18.0        0   8.264106         5.5   \n",
       "3                     0.0       7.0        1   8.828348        49.4   \n",
       "4                    40.0      19.0        0   9.718783        60.0   \n",
       "\n",
       "   total_acc  recoveries  collection_recovery_fee last_pymnt_d  \\\n",
       "0       36.0        0.00                    0.000     Apr-2020   \n",
       "1       60.0     5260.00                  946.800     Dec-2016   \n",
       "2       28.0      936.75                  168.615     Aug-2019   \n",
       "3        9.0        0.00                    0.000     Mar-2019   \n",
       "4       40.0        0.00                    0.000     Oct-2018   \n",
       "\n",
       "   last_fico_range_high  collections_12_mths_ex_med  acc_now_delinq  \\\n",
       "0                 764.0                           0               0   \n",
       "1                 639.0                           0               0   \n",
       "2                 609.0                           0               0   \n",
       "3                 744.0                           0               0   \n",
       "4                 669.0                           0               0   \n",
       "\n",
       "   tot_coll_amt  tot_cur_bal  open_acc_6m  open_act_il  open_il_12m  \\\n",
       "0             0      50054.0          1.0         10.0          3.0   \n",
       "1             0     606327.0          1.0         10.0          1.0   \n",
       "2             0     100922.0          1.0          2.0          0.0   \n",
       "3             0     194586.0          1.0          2.0          0.0   \n",
       "4             0     137528.0          0.0          0.0          0.0   \n",
       "\n",
       "   open_il_24m  mths_since_rcnt_il  total_bal_il  il_util  open_rv_12m  \\\n",
       "0          3.0                 3.0       46964.0     83.0          1.0   \n",
       "1          2.0                10.0      277552.0     90.0          4.0   \n",
       "2          2.0                15.0       28670.0     58.0          1.0   \n",
       "3          0.0               226.0        2749.0     23.0          0.0   \n",
       "4          0.0                 0.0           0.0      0.0          0.0   \n",
       "\n",
       "   open_rv_24m  max_bal_bc  all_util  total_rev_hi_lim  inq_last_12m  \\\n",
       "0          1.0    8.036250      64.0         10.003378           2.0   \n",
       "1          6.0    8.455105      85.0         10.317450           7.0   \n",
       "2          2.0    7.856320      27.0         11.157692           0.0   \n",
       "3          2.0    8.656433      37.0          9.532496           2.0   \n",
       "4          0.0    0.000000       0.0         10.229224           0.0   \n",
       "\n",
       "   acc_open_past_24mths  avg_cur_bal  bc_open_to_buy  bc_util  \\\n",
       "0                   4.0     8.256088        9.385218     20.6   \n",
       "1                   8.0    10.137175        8.702012     70.4   \n",
       "2                   5.0     8.689128       10.919080      6.6   \n",
       "3                   3.0    10.232755        7.814803     73.4   \n",
       "4                   6.0     8.941284        6.890609     91.1   \n",
       "\n",
       "   chargeoff_within_12_mths  delinq_amnt  mo_sin_old_il_acct  \\\n",
       "0                         0          0.0               147.0   \n",
       "1                         0          0.0               126.0   \n",
       "2                         0          0.0               134.0   \n",
       "3                         0          0.0               226.0   \n",
       "4                         0          0.0               149.0   \n",
       "\n",
       "   mo_sin_old_rev_tl_op  mo_sin_rcnt_rev_tl_op  mo_sin_rcnt_tl  mort_acc  \\\n",
       "0                 135.0                   12.0             3.0       1.0   \n",
       "1                 277.0                    6.0             6.0       2.0   \n",
       "2                 400.0                    6.0             6.0       3.0   \n",
       "3                 130.0                   14.0             5.0       1.0   \n",
       "4                 190.0                   13.0             9.0       1.0   \n",
       "\n",
       "   mths_since_recent_bc  mths_since_recent_inq  \\\n",
       "0                  56.0                    3.0   \n",
       "1                   7.0                    0.0   \n",
       "2                   6.0                   15.0   \n",
       "3                  14.0                    6.0   \n",
       "4                  20.0                    5.0   \n",
       "\n",
       "   mths_since_recent_revol_delinq  num_accts_ever_120_pd  num_actv_rev_tl  \\\n",
       "0                             0.0                    0.0              1.0   \n",
       "1                            10.0                    0.0             10.0   \n",
       "2                             0.0                    0.0              6.0   \n",
       "3                             0.0                    0.0              3.0   \n",
       "4                            43.0                    5.0             10.0   \n",
       "\n",
       "   num_bc_sats  num_bc_tl  num_il_tl  num_op_rev_tl  num_rev_accts  \\\n",
       "0          1.0        4.0       28.0            4.0            7.0   \n",
       "1          8.0       14.0       36.0           12.0           22.0   \n",
       "2          8.0        9.0        7.0           15.0           18.0   \n",
       "3          3.0        4.0        2.0            4.0            6.0   \n",
       "4          5.0       11.0       13.0           14.0           26.0   \n",
       "\n",
       "   num_rev_tl_bal_gt_0  num_sats  num_tl_120dpd_2m  num_tl_30dpd  \\\n",
       "0                  1.0      14.0                 0             0   \n",
       "1                 10.0      24.0                 0             0   \n",
       "2                  6.0      18.0                 0             0   \n",
       "3                  3.0       7.0                 0             0   \n",
       "4                 10.0      19.0                 0             0   \n",
       "\n",
       "   num_tl_90g_dpd_24m  num_tl_op_past_12m  pct_tl_nvr_dlq  percent_bc_gt_75  \\\n",
       "0                   0                 4.0            97.1               0.0   \n",
       "1                   0                 5.0            94.8              37.5   \n",
       "2                   0                 1.0           100.0               0.0   \n",
       "3                   0                 1.0            77.8              33.3   \n",
       "4                   0                 2.0            77.5             100.0   \n",
       "\n",
       "   pub_rec_bankruptcies  tax_liens  tot_hi_cred_lim  total_bal_ex_mort  \\\n",
       "0                     0          0        11.272280          10.820878   \n",
       "1                     0          0        13.386134          12.592905   \n",
       "2                     0          0        12.186584          10.390594   \n",
       "3                     1          0        12.263577           9.166806   \n",
       "4                     0          0        12.137612          11.101704   \n",
       "\n",
       "   total_bc_limit  total_il_high_credit_limit  default  addr_state_AK  \\\n",
       "0        9.615872                   10.942208        0              0   \n",
       "1        9.918425                   12.582679        1              0   \n",
       "2       10.987003                   10.806490        1              0   \n",
       "3        9.137877                    9.390242        0              0   \n",
       "4        9.305741                   11.199461        0              0   \n",
       "\n",
       "   addr_state_AL  addr_state_AR  addr_state_AZ  addr_state_CA  addr_state_CO  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   addr_state_CT  addr_state_DC  addr_state_DE  addr_state_FL  addr_state_GA  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              1              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   addr_state_HI  addr_state_IA  addr_state_ID  addr_state_IL  addr_state_IN  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              1              0   \n",
       "\n",
       "   addr_state_KS  addr_state_KY  addr_state_LA  addr_state_MA  addr_state_MD  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   addr_state_ME  addr_state_MI  addr_state_MN  addr_state_MO  addr_state_MS  \\\n",
       "0              0              0              1              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   addr_state_MT  addr_state_NC  addr_state_ND  addr_state_NE  addr_state_NH  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   addr_state_NJ  addr_state_NM  addr_state_NV  addr_state_NY  addr_state_OH  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   addr_state_OK  addr_state_OR  addr_state_PA  addr_state_RI  addr_state_SC  \\\n",
       "0              0              0              0              0              0   \n",
       "1              1              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   addr_state_SD  addr_state_TN  addr_state_TX  addr_state_UT  addr_state_VA  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              1              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   addr_state_VT  addr_state_WA  addr_state_WI  addr_state_WV  addr_state_WY  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   addr_state_nan  home_ownership_ANY  home_ownership_MORTGAGE  \\\n",
       "0               0                   0                        1   \n",
       "1               0                   0                        1   \n",
       "2               0                   0                        1   \n",
       "3               0                   0                        1   \n",
       "4               0                   0                        1   \n",
       "\n",
       "   home_ownership_NONE  home_ownership_OTHER  home_ownership_OWN  \\\n",
       "0                    0                     0                   0   \n",
       "1                    0                     0                   0   \n",
       "2                    0                     0                   0   \n",
       "3                    0                     0                   0   \n",
       "4                    0                     0                   0   \n",
       "\n",
       "   home_ownership_RENT  home_ownership_nan  purpose_car  purpose_credit_card  \\\n",
       "0                    0                   0            0                    0   \n",
       "1                    0                   0            0                    0   \n",
       "2                    0                   0            0                    0   \n",
       "3                    0                   0            0                    0   \n",
       "4                    0                   0            0                    1   \n",
       "\n",
       "   purpose_debt_consolidation  purpose_educational  purpose_home_improvement  \\\n",
       "0                           1                    0                         0   \n",
       "1                           1                    0                         0   \n",
       "2                           0                    0                         1   \n",
       "3                           0                    0                         1   \n",
       "4                           0                    0                         0   \n",
       "\n",
       "   purpose_house  purpose_major_purchase  purpose_medical  purpose_moving  \\\n",
       "0              0                       0                0               0   \n",
       "1              0                       0                0               0   \n",
       "2              0                       0                0               0   \n",
       "3              0                       0                0               0   \n",
       "4              0                       0                0               0   \n",
       "\n",
       "   purpose_other  purpose_renewable_energy  purpose_small_business  \\\n",
       "0              0                         0                       0   \n",
       "1              0                         0                       0   \n",
       "2              0                         0                       0   \n",
       "3              0                         0                       0   \n",
       "4              0                         0                       0   \n",
       "\n",
       "   purpose_vacation  purpose_wedding  purpose_nan  emp_length_missing  \\\n",
       "0                 0                0            0                   0   \n",
       "1                 0                0            0                   0   \n",
       "2                 0                0            0                   1   \n",
       "3                 0                0            0                   0   \n",
       "4                 0                0            0                   0   \n",
       "\n",
       "   percent_bc_gt_75_missing  mths_since_recent_inq_missing  \\\n",
       "0                         0                              0   \n",
       "1                         0                              0   \n",
       "2                         0                              0   \n",
       "3                         0                              0   \n",
       "4                         0                              0   \n",
       "\n",
       "   installment_missing  inq_last_6mths_missing  \\\n",
       "0                    0                       0   \n",
       "1                    0                       0   \n",
       "2                    0                       0   \n",
       "3                    0                       0   \n",
       "4                    0                       0   \n",
       "\n",
       "   mths_since_last_delinq_missing  total_acc_missing  recoveries_missing  \\\n",
       "0                               0                  0                   0   \n",
       "1                               0                  0                   0   \n",
       "2                               1                  0                   0   \n",
       "3                               1                  0                   0   \n",
       "4                               0                  0                   0   \n",
       "\n",
       "   open_acc_missing  all_util_missing  last_fico_range_high_missing  \\\n",
       "0                 0                 0                             0   \n",
       "1                 0                 0                             0   \n",
       "2                 0                 0                             0   \n",
       "3                 0                 0                             0   \n",
       "4                 0                 1                             0   \n",
       "\n",
       "   open_act_il_missing  total_bal_il_missing  revol_bal_missing  \\\n",
       "0                    0                     0                  0   \n",
       "1                    0                     0                  0   \n",
       "2                    0                     0                  0   \n",
       "3                    0                     0                  0   \n",
       "4                    1                     1                  0   \n",
       "\n",
       "   open_il_24m_missing  acc_now_delinq_missing  annual_inc_missing  \\\n",
       "0                    0                       0                   0   \n",
       "1                    0                       0                   0   \n",
       "2                    0                       0                   0   \n",
       "3                    0                       0                   0   \n",
       "4                    1                       0                   0   \n",
       "\n",
       "   pub_rec_missing  fico_range_low_missing  max_bal_bc_missing  \\\n",
       "0                0                       0                   0   \n",
       "1                0                       0                   0   \n",
       "2                0                       0                   0   \n",
       "3                0                       0                   0   \n",
       "4                0                       0                   1   \n",
       "\n",
       "   delinq_2yrs_missing  open_rv_12m_missing  open_acc_6m_missing  \\\n",
       "0                    0                    0                    0   \n",
       "1                    0                    0                    0   \n",
       "2                    0                    0                    0   \n",
       "3                    0                    0                    0   \n",
       "4                    0                    1                    1   \n",
       "\n",
       "   delinq_amnt_missing  open_rv_24m_missing  \\\n",
       "0                    0                    0   \n",
       "1                    0                    0   \n",
       "2                    0                    0   \n",
       "3                    0                    0   \n",
       "4                    0                    1   \n",
       "\n",
       "   mths_since_recent_revol_delinq_missing  fico_range_high_missing  \\\n",
       "0                                       1                        0   \n",
       "1                                       0                        0   \n",
       "2                                       1                        0   \n",
       "3                                       1                        0   \n",
       "4                                       0                        0   \n",
       "\n",
       "   funded_amnt_missing  inq_last_12m_missing  collection_recovery_fee_missing  \\\n",
       "0                    0                     0                                0   \n",
       "1                    0                     0                                0   \n",
       "2                    0                     0                                0   \n",
       "3                    0                     0                                0   \n",
       "4                    0                     1                                0   \n",
       "\n",
       "   mths_since_rcnt_il_missing  open_il_12m_missing  il_util_missing  \n",
       "0                           0                    0                0  \n",
       "1                           0                    0                0  \n",
       "2                           0                    0                0  \n",
       "3                           0                    0                0  \n",
       "4                           1                    1                1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "136e5c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 독립변수에서 제외할 변수 목록\n",
    "drop_cols = [\n",
    "    'term', 'last_pymnt_d', 'installment', 'funded_amnt',\n",
    "    'recoveries', 'collection_recovery_fee', 'default', 'issue_d'\n",
    "]\n",
    "\n",
    "X = df.drop(columns=drop_cols)\n",
    "y = df['default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ef5ee99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fredapi in c:\\users\\seon\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.5.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\seon\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fredapi) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\seon\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->fredapi) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\seon\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->fredapi) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\seon\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->fredapi) (1.22.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\seon\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->fredapi) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install fredapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "545bba80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1953-04-01    2.51\n",
      "1953-05-01    2.72\n",
      "1953-06-01    2.74\n",
      "1953-07-01    2.62\n",
      "1953-08-01    2.58\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from fredapi import Fred\n",
    "\n",
    "# FRED API 연결\n",
    "fred = Fred(api_key=\"f9ef939a9a1eeff85d31ed2c984507d9\")  # 🔑 실제 API 키로 대체해야 함\n",
    "\n",
    "# 미국 3년 만기 국채 수익률(GS3) 시계열 불러오기\n",
    "series = fred.get_series('GS3')  # pandas.Series 형식으로 반환됨\n",
    "\n",
    "\n",
    "print(series.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9258fd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearest_rate(issue_date, rate_series):\n",
    "    if pd.isnull(issue_date):\n",
    "        return np.nan\n",
    "    try:\n",
    "        idx = rate_series.index.get_indexer([issue_date], method='nearest')[0]\n",
    "        return rate_series.iloc[idx] / 100  # % 단위 → 소수로 변환\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {issue_date} ▶ {e}\")\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "df['risk_free_rate'] = df['issue_d'].apply(lambda x: get_nearest_rate(x, series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8e706ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      issue_d  risk_free_rate last_pymnt_d\n",
      "0  2017-12-01          0.0196     Apr-2020\n",
      "1  2016-07-01          0.0079     Dec-2016\n",
      "2  2017-10-01          0.0168     Aug-2019\n",
      "3  2017-05-01          0.0148     Mar-2019\n",
      "4  2015-09-01          0.0101     Oct-2018\n"
     ]
    }
   ],
   "source": [
    "print(df[['issue_d', 'risk_free_rate', 'last_pymnt_d']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc85bc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "def create_cash_flow_from_dates(row):\n",
    "    try:\n",
    "        term = int(row['term'])\n",
    "        default = int(row['default'])\n",
    "        issue_d = pd.to_datetime(row['issue_d'])  # 이미 datetime 형식\n",
    "        last_pymnt_d = pd.to_datetime(row['last_pymnt_d'])  # 이건 문자열일 수도 있으니 변환\n",
    "        installment = float(row['installment'])\n",
    "        funded_amnt = float(row['funded_amnt'])\n",
    "        recoveries = float(row['recoveries'])\n",
    "        collection_fee = float(row['collection_recovery_fee'])\n",
    "\n",
    "        # 첫 현금흐름: 대출 실행\n",
    "        cash_flow = [-funded_amnt]\n",
    "\n",
    "        if pd.isnull(issue_d) or pd.isnull(last_pymnt_d):\n",
    "            return np.nan\n",
    "\n",
    "        # 몇 회차까지 납입했는지 계산\n",
    "        delta = relativedelta(last_pymnt_d, issue_d)\n",
    "        last_pymnt_num = delta.years * 12 + delta.months\n",
    "\n",
    "        for month in range(1, term + 1):\n",
    "            if default == 1:\n",
    "                if month <= last_pymnt_num:\n",
    "                    cash_flow.append(installment)\n",
    "                elif month == last_pymnt_num + 1:\n",
    "                    cash_flow.append(recoveries - collection_fee)\n",
    "                else:\n",
    "                    cash_flow.append(0)\n",
    "            else:\n",
    "                cash_flow.append(installment)\n",
    "\n",
    "        return cash_flow\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[오류] index={row.name}, error={e}\")\n",
    "        return np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11e628eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cash_flow'] = df.apply(create_cash_flow_from_dates, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a05c244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy-financial in c:\\users\\seon\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\seon\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from numpy-financial) (1.22.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy-financial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22503c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy_financial as npf\n",
    "\n",
    "def get_irr(cash_flow):\n",
    "    if not isinstance(cash_flow, list) or len(cash_flow) == 0:\n",
    "        return np.nan\n",
    "    irr_monthly = npf.irr(cash_flow)\n",
    "    if irr_monthly is None or np.isnan(irr_monthly):\n",
    "        return np.nan\n",
    "    return (1 + irr_monthly) ** 12 - 1  # 연환산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e179c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['irr'] = df['cash_flow'].apply(get_irr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f58e01a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['irr'] = df['irr'].fillna(df['risk_free_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afcbd651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 저장용 리스트\n",
    "best_thresholds = []\n",
    "validation_sharpes = []\n",
    "test_sharpes = []\n",
    "test_approval_rates = []\n",
    "test_irr_means = []\n",
    "test_irr_positive_rates = []\n",
    "\n",
    "\n",
    "# Sharpe 계산 함수\n",
    "def calculate_sharpe(returns, risk_free_rates):\n",
    "    excess = returns - risk_free_rates\n",
    "    if excess.std(ddof=1) == 0:\n",
    "        return -np.inf\n",
    "    return excess.mean() / excess.std(ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfc7dd7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:20:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:21:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:21:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:21:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:21:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:22:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:22:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:22:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:22:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:22:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:23:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best hyperparameters (from tuning): {'subsample': 1.0, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.3, 'colsample_bytree': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:23:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:24:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:25:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:26:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:26:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:27:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:28:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:29:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:30:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:31:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:32:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:33:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:33:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:34:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:35:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:36:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:37:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:37:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:38:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:39:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:40:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:41:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:41:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:42:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:43:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:44:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:45:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:46:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:47:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:47:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:48:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:49:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:50:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:51:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:52:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:52:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:53:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:54:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:55:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:56:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:57:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:58:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:58:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:59:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:00:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:01:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:02:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:04:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:04:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:05:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:06:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:07:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:08:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:09:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:10:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:11:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:11:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:12:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:13:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:14:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:15:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:16:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:17:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:18:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:18:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:19:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:20:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:21:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:22:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:23:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:24:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:25:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:25:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:26:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:27:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:28:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:29:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:30:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:31:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:31:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:32:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:33:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:34:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:35:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:36:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:37:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:38:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:39:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:40:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:40:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:41:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:42:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:43:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:44:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:45:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:46:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:46:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:47:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\seon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:48:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best model index: 30\n",
      "✅ Best validation Sharpe ratio: 0.6755643154286598\n",
      "✅ Best test Sharpe ratio: 1.1175044374479914\n",
      "✅ Best approval rate: 0.5938843893348624\n",
      "✅ Mean IRR: 0.12070204899809747\n",
      "✅ Positive IRR ratio: 0.9900055817882842\n",
      "✅ Best threshold: 0.05\n",
      "✅ Best model params: {'objective': 'binary:logistic', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.8, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'logloss', 'feature_types': None, 'feature_weights': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.3, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 3, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 100, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': None, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': 1.0, 'tree_method': None, 'validate_parameters': None, 'verbosity': None, 'use_label_encoder': False}\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 결과 저장용 리스트\n",
    "best_models = []\n",
    "best_thresholds = []\n",
    "validation_sharpes = []\n",
    "test_sharpes = []\n",
    "test_approval_rates = []\n",
    "test_irr_means = []\n",
    "test_irr_positive_rates = []\n",
    "\n",
    "# 하이퍼파라미터 범위 지정\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.3],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# 튜닝용 고정된 데이터셋으로 하이퍼파라미터 탐색 1회 수행\n",
    "X_tune, _, y_tune, _ = train_test_split(X, y, test_size=0.3, stratify=y)\n",
    "\n",
    "model_base = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "search = RandomizedSearchCV(\n",
    "    model_base, param_distributions=param_dist, n_iter=5,\n",
    "    scoring='roc_auc', cv=2, n_jobs=1\n",
    ")\n",
    "search.fit(X_tune, y_tune)\n",
    "\n",
    "best_params = search.best_params_\n",
    "print(\"✅ Best hyperparameters (from tuning):\", best_params)\n",
    "\n",
    "# 해당 best 파라미터를 기반으로 100번 반복 학습 및 평가\n",
    "for i in range(100):\n",
    "    # Train-test split\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=i, stratify=y\n",
    "    )\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.25, random_state=i, stratify=y_temp\n",
    "    )\n",
    "\n",
    "    # best 하이퍼파라미터로 모델 생성 및 학습\n",
    "    model = XGBClassifier(**best_params, use_label_encoder=False, eval_metric='logloss')\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 검증 세트 예측 및 threshold 탐색\n",
    "    y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "    thresholds = np.arange(0.0, 0.95, 0.05)\n",
    "\n",
    "    best_sharpe = -np.inf\n",
    "    best_threshold = None\n",
    "    val_indices = X_val.index\n",
    "    df_val = df.loc[val_indices]\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        approved_mask = y_pred_proba <= threshold\n",
    "        denied_mask = ~approved_mask\n",
    "\n",
    "        selected = df_val.copy()\n",
    "        selected.loc[approved_mask, 'irr_adj'] = selected.loc[approved_mask, 'irr']\n",
    "        selected.loc[denied_mask, 'irr_adj'] = selected.loc[denied_mask, 'risk_free_rate']\n",
    "\n",
    "        returns = selected['irr_adj']\n",
    "        risk_free = selected['risk_free_rate']\n",
    "        valid = returns.notnull() & risk_free.notnull()\n",
    "\n",
    "        if valid.sum() < 2:\n",
    "            continue\n",
    "\n",
    "        sharpe = calculate_sharpe(returns[valid], risk_free[valid])\n",
    "\n",
    "        if sharpe > best_sharpe:\n",
    "            best_sharpe = sharpe\n",
    "            best_threshold = threshold\n",
    "\n",
    "    best_models.append(model)\n",
    "    best_thresholds.append(best_threshold)\n",
    "    validation_sharpes.append(best_sharpe)\n",
    "\n",
    "    # Test 데이터 평가\n",
    "    y_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "    test_approved_mask = y_test_proba <= best_threshold\n",
    "    df_test = df.loc[X_test.index]\n",
    "    test_selected = df_test[test_approved_mask]\n",
    "\n",
    "    returns_test = test_selected['irr']\n",
    "    risk_free_test = test_selected['risk_free_rate']\n",
    "    valid = returns_test.notnull() & risk_free_test.notnull()\n",
    "\n",
    "    returns_test = returns_test[valid]\n",
    "    risk_free_test = risk_free_test[valid]\n",
    "\n",
    "    sharpe_test = calculate_sharpe(returns_test, risk_free_test)\n",
    "    test_sharpes.append(sharpe_test)\n",
    "    test_approval_rates.append(len(returns_test) / len(df_test))\n",
    "    test_irr_means.append(returns_test.mean())\n",
    "    test_irr_positive_rates.append((returns_test > 0).mean())\n",
    "\n",
    "# 최종 결과 출력\n",
    "best_idx = np.argmax(test_sharpes)\n",
    "print(\"✅ Best model index:\", best_idx)\n",
    "print(\"✅ Best validation Sharpe ratio:\", validation_sharpes[best_idx])\n",
    "print(\"✅ Best test Sharpe ratio:\", test_sharpes[best_idx])\n",
    "print(\"✅ Best approval rate:\", test_approval_rates[best_idx])\n",
    "print(\"✅ Mean IRR:\", test_irr_means[best_idx])\n",
    "print(\"✅ Positive IRR ratio:\", test_irr_positive_rates[best_idx])\n",
    "print(\"✅ Best threshold:\", best_thresholds[best_idx])\n",
    "print(\"✅ Best model params:\", best_models[best_idx].get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51cfecd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best thresholds from 2 runs:\n",
      "[0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05]\n",
      "\n",
      "Validation Sharpe Ratios from 2 runs:\n",
      "[0.686894172264285, 0.6892548986112442, 0.6898597969861889, 0.6858177106803915, 0.6980715886578543, 0.6918641488651484, 0.696138118562637, 0.6918565933375201, 0.6872636602005415, 0.6844663473808295, 0.6907044678117407, 0.6928223106458958, 0.6904066738495807, 0.6828844286534033, 0.6834478331669691, 0.6866324125014132, 0.6872175880329715, 0.6902529394385192, 0.6829299871404768, 0.69890653910196, 0.6877466654346027, 0.6909811000816011, 0.6843206367970848, 0.6998522303440098, 0.6873674138819255, 0.6851696287179679, 0.6815880431713284, 0.6916939271202167, 0.6898287692988205, 0.6812669970312458, 0.6755643154286598, 0.6877346709869788, 0.6858437519473064, 0.6938569582805711, 0.6975372122817072, 0.682483147390265, 0.6910343260905358, 0.6958687568624943, 0.6925022506836945, 0.6869814303883518, 0.6895877758366349, 0.6950564039154535, 0.6856549023775141, 0.696729636088734, 0.6909289761448252, 0.6839946187429687, 0.6990891759712053, 0.6863190705676623, 0.6895084079671424, 0.6802527504919644, 0.682509383213485, 0.6935307415948625, 0.6957775181465327, 0.6852306119092989, 0.682971782146208, 0.6860105961198674, 0.6937581572520779, 0.6860556178699715, 0.6881455523711852, 0.6927442782501161, 0.6955570037699862, 0.6876816281572719, 0.6878102479496643, 0.6825812230505303, 0.7032587349676329, 0.6941672945261481, 0.6818943650440242, 0.6804178982439144, 0.6910896253973804, 0.6905201853370221, 0.6829196482132717, 0.7033500645122684, 0.6853667322595919, 0.6908990795439515, 0.6909523104923948, 0.7006158933070352, 0.703032365048976, 0.6952577975256441, 0.6947624351685461, 0.6836801447936587, 0.686284732142918, 0.6927151143618181, 0.6864584158280063, 0.6876181998572705, 0.6870153252388763, 0.6948440074134223, 0.6902455535094081, 0.6997499500998343, 0.6934018461946322, 0.7031012176500904, 0.6836358198095754, 0.6845796895975166, 0.6853143425204091, 0.689375502797537, 0.677933786955594, 0.6853695599890037, 0.6829381507267797, 0.6905268008293873, 0.6798054472352338, 0.6908835635569214]\n",
      "\n",
      "Test Sharpe Ratios from 2 runs:\n",
      "[1.0761808093156064, 1.0915409505136833, 1.061042827464492, 1.0833588883764187, 1.0761834563421395, 1.1170066474772629, 1.1049391346242257, 1.0853260222520376, 1.0675716465936398, 1.0805107429107634, 1.063908322685278, 1.1173011288477226, 1.0792165519026076, 1.071684629154181, 1.0941855950940083, 1.064826060260682, 1.052830899774698, 1.0894912751625885, 1.0625449268462612, 1.062484634509286, 1.0882982225198268, 1.0814284590015475, 1.082518074444871, 1.1064895419984992, 1.0734901600817541, 1.0954208584639353, 1.0916128566277916, 1.0982292177004533, 1.081031902495404, 1.09400234207671, 1.1175044374479914, 1.0991299372127832, 1.0764236732969898, 1.0887860393032547, 1.0811579131368638, 1.0877523872300647, 1.08220482419127, 1.0657239593666679, 1.0727666157671703, 1.0626274399438063, 1.0692505358691353, 1.069405376392811, 1.0581439337974745, 1.0690717647261208, 1.0782390876288193, 1.1025020188668855, 1.0825753130067968, 1.0752334219808948, 1.0476569033112821, 1.0856660889770877, 1.0778674438086537, 1.1101116037187688, 1.0736727056120616, 1.0668850596980413, 1.0862108446226617, 1.0742108664289638, 1.0662050331788395, 1.0843252234605372, 1.063916913759226, 1.071261806922, 1.0645276364402545, 1.0680750669336072, 1.0981497018566713, 1.086642511831576, 1.0662925297672223, 1.0664532429131908, 1.1113949916168557, 1.0692057024009427, 1.0769823715847215, 1.0952709402406169, 1.069948947081966, 1.0734843770799385, 1.0652281987998957, 1.0919050628857068, 1.0996378215085965, 1.0738569290358257, 1.0648133556574657, 1.08938477607455, 1.070369044440499, 1.093776909990557, 1.084771808975789, 1.059169108308192, 1.088093557489283, 1.0986796769978011, 1.0874246373858747, 1.0906650776603808, 1.077132225195949, 1.064980151850586, 1.1006451308149519, 1.0764092753487144, 1.089554952668751, 1.09844628344919, 1.0714726149397176, 1.082733227229473, 1.0811216007389568, 1.085445371748101, 1.075217312686339, 1.074767413855958, 1.0826606849756226, 1.0635139986512134]\n",
      "\n",
      "Test Approval Rates:\n",
      "[0.5973113173738532, 0.5967424025229358, 0.5986059346330275, 0.5969484661697247, 0.5968185564793578, 0.5966707282110092, 0.5973157970183486, 0.5987358443233946, 0.5993092388188074, 0.5984043506307339, 0.5977592818233946, 0.5956986453555045, 0.5958688718463303, 0.5991300530389908, 0.5997706422018348, 0.5981803684059633, 0.5968454343463303, 0.5968991900802753, 0.5982341241399083, 0.598762722190367, 0.5958957497133027, 0.5957971975344036, 0.5991300530389908, 0.5956628081995413, 0.5989867044151376, 0.5976248924885321, 0.5991390123279816, 0.5956807267775229, 0.59765625, 0.5990046229931193, 0.5938843893348624, 0.5974098695527523, 0.6005366614105505, 0.5966304114105505, 0.5977458428899083, 0.5981803684059633, 0.5959584647362385, 0.5975218606651376, 0.5956448896215596, 0.5961690080275229, 0.5964019495412844, 0.5964601849197247, 0.5978354357798165, 0.5953133959288991, 0.5982027666284404, 0.6003216384747706, 0.599945348337156, 0.5994436281536697, 0.5977592818233946, 0.5983595541857798, 0.5981624498279816, 0.5948833500573395, 0.5967782396788991, 0.5987806407683486, 0.5958733514908257, 0.5963481938073395, 0.5961690080275229, 0.5982251648509175, 0.5979563861811926, 0.5972844395068807, 0.5983416356077982, 0.5964825831422018, 0.5977637614678899, 0.598502902809633, 0.5978399154243119, 0.5976428110665137, 0.5981803684059633, 0.5971455705275229, 0.595909188646789, 0.5981714091169725, 0.5993405963302753, 0.5971366112385321, 0.5986283328555045, 0.5980638976490825, 0.5964333070527523, 0.5978578340022935, 0.5990225415711009, 0.5983909116972477, 0.5982296444954128, 0.5973113173738532, 0.5964870627866973, 0.5982610020068807, 0.5996183342889908, 0.5947579200114679, 0.5981310923165137, 0.5962765194954128, 0.5967065653669725, 0.5978802322247706, 0.5986686496559633, 0.5987716814793578, 0.5974546659977065, 0.5945652952981652, 0.6001424526949541, 0.6003126791857798, 0.5985476992545872, 0.5943950688073395, 0.5971097333715596, 0.5992375645068807, 0.5974546659977065, 0.596961905103211]\n",
      "\n",
      "Test IRR Means:\n",
      "[0.12007022383602359, 0.12042750260632112, 0.11995181473511259, 0.1203472992510848, 0.12010851869543736, 0.1209784886927739, 0.12070224115496911, 0.12011318282369662, 0.11987948177886981, 0.12023244734881884, 0.12010704353345432, 0.12106055417820522, 0.12012302211194474, 0.12014657759246598, 0.12041582552810982, 0.11986416776880027, 0.11966095020437535, 0.12039448558458404, 0.12022933312467587, 0.12001375520780001, 0.1203682208447993, 0.12013428619753037, 0.12040281938944813, 0.12057828988734029, 0.1203988141386273, 0.1205466888219459, 0.12014544038530767, 0.12051699341571659, 0.12034362099282296, 0.1205752757344678, 0.12070204899809747, 0.12057374501689086, 0.12014531815368588, 0.1204667059831564, 0.1204569632866592, 0.12048535080145753, 0.12039511996701606, 0.1200466050001217, 0.1202303897449589, 0.12015183100219298, 0.1202929131347721, 0.11985939098529239, 0.1199611035270418, 0.12015402702065806, 0.12019557987645649, 0.120811763039864, 0.1201074437375685, 0.12019642427531509, 0.11968064753289784, 0.12028656897302156, 0.12016666815517095, 0.12051866678712705, 0.12029808819958067, 0.11986835742014713, 0.12035820453458611, 0.1200410331582404, 0.11987987558594371, 0.1206805207530356, 0.12009515969539213, 0.12015740139115844, 0.12017981186356944, 0.12008925497175772, 0.12081142559314369, 0.12067793221972575, 0.11999982150816889, 0.11989793591237145, 0.12090475600830629, 0.12020403669198217, 0.12010251862515954, 0.12033111244398784, 0.11998681408718315, 0.11995704750726413, 0.12014953213119246, 0.12046448483495541, 0.1206327350334955, 0.12026256731484267, 0.12021097531543766, 0.12059678309339995, 0.12020541670431183, 0.12059927215979988, 0.12036270067852693, 0.12011481324199151, 0.12043153358384907, 0.12040065201878686, 0.12058206749163948, 0.12020185680122683, 0.1202859140695831, 0.12015221517682206, 0.12055188322709313, 0.1202632450798321, 0.12042121700768033, 0.12038120889420184, 0.12017910766835233, 0.12051576745526674, 0.12036064100405178, 0.1203732668360375, 0.12022404531548704, 0.12026914862700297, 0.12028314341187832, 0.12001981864293802]\n",
      "\n",
      "Test IRR Positive Rates:\n",
      "[0.9895604436811436, 0.9897231480647389, 0.9893360672912862, 0.9895991235047802, 0.9892966246087563, 0.9900447460884712, 0.9897255137243138, 0.9893982357826376, 0.9890570691781589, 0.9894223067306469, 0.9894033978072377, 0.9901563404748118, 0.9893547441304494, 0.9891360424688773, 0.9896854086998088, 0.9890588843207297, 0.989019401808834, 0.9895982648765076, 0.9891272604739976, 0.9892116741356994, 0.9896108191816453, 0.9896166194239141, 0.9897566264159408, 0.9898925329583143, 0.9895896434901618, 0.9895434341011476, 0.9896296739366116, 0.9897273923669863, 0.9897388619056185, 0.9897843954022301, 0.9900055817882842, 0.9895696642946589, 0.989415108273223, 0.9896836778364255, 0.9894781018615666, 0.9897104086630271, 0.9894841284755369, 0.9889343709234852, 0.9894936337587522, 0.9893225331369662, 0.9893116812883067, 0.9892601521603617, 0.9890001198897015, 0.9895103579571535, 0.9894861387769773, 0.9899709725321055, 0.9894644097157407, 0.9893958076448829, 0.9892535165881039, 0.9893616224835857, 0.9895752982498184, 0.9899997740912821, 0.9893259270379823, 0.9891820718651575, 0.989648017561533, 0.9895135362519155, 0.9892323645216555, 0.9896587615973881, 0.9891521766816748, 0.9894099735249338, 0.9893238700596695, 0.9895759796926866, 0.9899730215827338, 0.9896710452453127, 0.9892025146676457, 0.9894388103108392, 0.990009960084773, 0.9892724790325726, 0.9894381549471531, 0.9899349214789075, 0.9893790361157618, 0.9895873968492123, 0.9890446222115795, 0.9896784438269154, 0.9900107403318237, 0.9893976517484508, 0.9892537447371766, 0.9897888905524779, 0.9892020607440244, 0.9897629350752593, 0.9898689497202509, 0.9890903100688127, 0.9895856679665904, 0.9898394956654039, 0.9895972199337937, 0.989670042371608, 0.9894973123930212, 0.9892257204081939, 0.9898310411397615, 0.9893913889200614, 0.9896154336399967, 0.9897683950394045, 0.9894902628180726, 0.9893962345812595, 0.9894772293529918, 0.9897654648498734, 0.9892418263387699, 0.9894594412756319, 0.9896304294036935, 0.9894417721613975]\n"
     ]
    }
   ],
   "source": [
    "print(\"Best thresholds from 2 runs:\")\n",
    "print(best_thresholds)\n",
    "\n",
    "print(\"\\nValidation Sharpe Ratios from 2 runs:\")\n",
    "print(validation_sharpes)\n",
    "\n",
    "print(\"\\nTest Sharpe Ratios from 2 runs:\")\n",
    "print(test_sharpes)\n",
    "\n",
    "print(\"\\nTest Approval Rates:\")\n",
    "print(test_approval_rates)\n",
    "\n",
    "print(\"\\nTest IRR Means:\")\n",
    "print(test_irr_means)\n",
    "\n",
    "print(\"\\nTest IRR Positive Rates:\")\n",
    "print(test_irr_positive_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ceb2297",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
