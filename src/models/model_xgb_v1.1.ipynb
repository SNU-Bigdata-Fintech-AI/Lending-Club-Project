{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b739aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas numpy scikit-learn xgboost tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc17fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04320ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS S3ì—ì„œ ë°ì´í„° load\n",
    "tqdm.pandas()\n",
    "url = \"https://snu-bigdata-fintech-ai.s3.ap-northeast-2.amazonaws.com/data/interim/preprocessed_data_ver.2.3.(IRR%2BLOG%2BBINARY).csv\"\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8914423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë“  ì—´ ë‹¤ ë³´ê¸°\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# ëª¨ë“  í–‰ ë‹¤ ë³´ê¸°\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# ì—´ ë„ˆë¹„ ë„‰ë„‰í•˜ê²Œ\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "# ì—´ ì•ˆì˜ ê°’ ìë¥´ì§€ ì•Šê²Œ\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ad51c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136e5c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë…ë¦½ë³€ìˆ˜ì—ì„œ ì œì™¸í•  ë³€ìˆ˜ ëª©ë¡\n",
    "drop_cols = [\n",
    "    'term', 'last_pymnt_d', 'installment', 'funded_amnt',\n",
    "    'recoveries', 'collection_recovery_fee', 'default', 'issue_d'\n",
    "]\n",
    "\n",
    "X = df.drop(columns=drop_cols)\n",
    "y = df['default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef5ee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fredapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545bba80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fredapi import Fred\n",
    "\n",
    "# FRED API ì—°ê²°\n",
    "fred = Fred(api_key=\"f9ef939a9a1eeff85d31ed2c984507d9\")  # ğŸ”‘ ì‹¤ì œ API í‚¤ë¡œ ëŒ€ì²´í•´ì•¼ í•¨\n",
    "\n",
    "# ë¯¸êµ­ 3ë…„ ë§Œê¸° êµ­ì±„ ìˆ˜ìµë¥ (GS3) ì‹œê³„ì—´ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "series = fred.get_series('GS3')  # pandas.Series í˜•ì‹ìœ¼ë¡œ ë°˜í™˜ë¨\n",
    "\n",
    "\n",
    "print(series.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9258fd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearest_rate(issue_date, rate_series):\n",
    "    if pd.isnull(issue_date):\n",
    "        return np.nan\n",
    "    try:\n",
    "        idx = rate_series.index.get_indexer([issue_date], method='nearest')[0]\n",
    "        return rate_series.iloc[idx] / 100  # % ë‹¨ìœ„ â†’ ì†Œìˆ˜ë¡œ ë³€í™˜\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {issue_date} â–¶ {e}\")\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "df['risk_free_rate'] = df['issue_d'].apply(lambda x: get_nearest_rate(x, series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e706ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[['issue_d', 'risk_free_rate', 'last_pymnt_d']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc85bc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "def create_cash_flow_from_dates(row):\n",
    "    try:\n",
    "        term = int(row['term'])\n",
    "        default = int(row['default'])\n",
    "        issue_d = pd.to_datetime(row['issue_d'])  # ì´ë¯¸ datetime í˜•ì‹\n",
    "        last_pymnt_d = pd.to_datetime(row['last_pymnt_d'])  # ì´ê±´ ë¬¸ìì—´ì¼ ìˆ˜ë„ ìˆìœ¼ë‹ˆ ë³€í™˜\n",
    "        installment = float(row['installment'])\n",
    "        funded_amnt = float(row['funded_amnt'])\n",
    "        recoveries = float(row['recoveries'])\n",
    "        collection_fee = float(row['collection_recovery_fee'])\n",
    "\n",
    "        # ì²« í˜„ê¸ˆíë¦„: ëŒ€ì¶œ ì‹¤í–‰\n",
    "        cash_flow = [-funded_amnt]\n",
    "\n",
    "        if pd.isnull(issue_d) or pd.isnull(last_pymnt_d):\n",
    "            return np.nan\n",
    "\n",
    "        # ëª‡ íšŒì°¨ê¹Œì§€ ë‚©ì…í–ˆëŠ”ì§€ ê³„ì‚°\n",
    "        delta = relativedelta(last_pymnt_d, issue_d)\n",
    "        last_pymnt_num = delta.years * 12 + delta.months\n",
    "\n",
    "        for month in range(1, term + 1):\n",
    "            if default == 1:\n",
    "                if month <= last_pymnt_num:\n",
    "                    cash_flow.append(installment)\n",
    "                elif month == last_pymnt_num + 1:\n",
    "                    cash_flow.append(recoveries - collection_fee)\n",
    "                else:\n",
    "                    cash_flow.append(0)\n",
    "            else:\n",
    "                cash_flow.append(installment)\n",
    "\n",
    "        return cash_flow\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ì˜¤ë¥˜] index={row.name}, error={e}\")\n",
    "        return np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e628eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cash_flow'] = df.apply(create_cash_flow_from_dates, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a05c244",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy-financial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22503c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy_financial as npf\n",
    "\n",
    "def get_irr(cash_flow):\n",
    "    if not isinstance(cash_flow, list) or len(cash_flow) == 0:\n",
    "        return np.nan\n",
    "    irr_monthly = npf.irr(cash_flow)\n",
    "    if irr_monthly is None or np.isnan(irr_monthly):\n",
    "        return np.nan\n",
    "    return (1 + irr_monthly) ** 12 - 1  # ì—°í™˜ì‚°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e179c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['irr'] = df['cash_flow'].apply(get_irr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58e01a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['irr'] = df['irr'].fillna(df['risk_free_rate'])\n",
    "df.to_csv('../../data/interim/preprocessed_dat_ver.3.0.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcbd651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸\n",
    "best_thresholds = []\n",
    "validation_sharpes = []\n",
    "test_sharpes = []\n",
    "test_approval_rates = []\n",
    "test_irr_means = []\n",
    "test_irr_positive_rates = []\n",
    "\n",
    "\n",
    "# Sharpe ê³„ì‚° í•¨ìˆ˜\n",
    "def calculate_sharpe(returns, risk_free_rates):\n",
    "    excess = returns - risk_free_rates\n",
    "    if excess.std(ddof=1) == 0:\n",
    "        return -np.inf\n",
    "    return excess.mean() / excess.std(ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed76cd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# í•˜ì´í¼íŒŒë¼ë¯¸í„° ë²”ìœ„ ì§€ì •\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0, 1, 5],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'reg_alpha': [0, 0.1, 1],\n",
    "    'reg_lambda': [1, 5, 10]\n",
    "}\n",
    "\n",
    "# íŠœë‹ìš© ê³ ì •ëœ ë°ì´í„°ì…‹ìœ¼ë¡œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰ 1íšŒ ìˆ˜í–‰\n",
    "X_tune, _, y_tune, _ = train_test_split(X, y, test_size=0.3, stratify=y)\n",
    "\n",
    "model_base = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "search = RandomizedSearchCV(\n",
    "    model_base, param_distributions=param_dist, n_iter=9,\n",
    "    scoring='roc_auc', cv=2, n_jobs=1\n",
    ")\n",
    "search.fit(X_tune, y_tune)\n",
    "\n",
    "best_params = search.best_params_\n",
    "print(\"âœ… Best hyperparameters (from tuning):\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc7dd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸\n",
    "best_models = []\n",
    "best_thresholds = []\n",
    "validation_sharpes = []\n",
    "test_sharpes = []\n",
    "test_approval_rates = []\n",
    "test_irr_means = []\n",
    "test_irr_positive_rates = []\n",
    "\n",
    "# í•´ë‹¹ best íŒŒë¼ë¯¸í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ 100ë²ˆ ë°˜ë³µ í•™ìŠµ ë° í‰ê°€\n",
    "for i in tqdm(range(100)):\n",
    "    # Train-test split\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=i, stratify=y\n",
    "    )\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.25, random_state=i, stratify=y_temp\n",
    "    )\n",
    "\n",
    "    # best í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ ëª¨ë¸ ìƒì„± ë° í•™ìŠµ\n",
    "    model = XGBClassifier(**best_params, eval_metric='logloss')\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # ê²€ì¦ ì„¸íŠ¸ ì˜ˆì¸¡ ë° threshold íƒìƒ‰\n",
    "    y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "    thresholds = np.arange(0.0, 1.0, 0.05)\n",
    "\n",
    "    best_sharpe = -np.inf\n",
    "    best_threshold = None\n",
    "    val_indices = X_val.index\n",
    "    df_val = df.loc[val_indices]\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        approved_mask = y_pred_proba <= threshold\n",
    "        denied_mask = ~approved_mask\n",
    "\n",
    "        selected = df_val.copy()\n",
    "        selected.loc[approved_mask, 'irr_adj'] = selected.loc[approved_mask, 'irr']\n",
    "        selected.loc[denied_mask, 'irr_adj'] = selected.loc[denied_mask, 'risk_free_rate']\n",
    "\n",
    "        returns = selected['irr_adj']\n",
    "        risk_free = selected['risk_free_rate']\n",
    "        valid = returns.notnull() & risk_free.notnull()\n",
    "\n",
    "        if valid.sum() < 2:\n",
    "            continue\n",
    "\n",
    "        sharpe = calculate_sharpe(returns[valid], risk_free[valid])\n",
    "\n",
    "        if sharpe > best_sharpe:\n",
    "            best_sharpe = sharpe\n",
    "            best_threshold = threshold\n",
    "\n",
    "    best_models.append(model)\n",
    "    best_thresholds.append(best_threshold)\n",
    "    validation_sharpes.append(best_sharpe)\n",
    "\n",
    "    # Test ë°ì´í„° í‰ê°€\n",
    "    y_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "    test_approved_mask = y_test_proba <= best_threshold\n",
    "    df_test = df.loc[X_test.index]\n",
    "    test_selected = df_test[test_approved_mask]\n",
    "\n",
    "    returns_test = test_selected['irr']\n",
    "    risk_free_test = test_selected['risk_free_rate']\n",
    "    valid = returns_test.notnull() & risk_free_test.notnull()\n",
    "\n",
    "    returns_test = returns_test[valid]\n",
    "    risk_free_test = risk_free_test[valid]\n",
    "\n",
    "    sharpe_test = calculate_sharpe(returns_test, risk_free_test)\n",
    "    test_sharpes.append(sharpe_test)\n",
    "    test_approval_rates.append(len(returns_test) / len(df_test))\n",
    "    test_irr_means.append(returns_test.mean())\n",
    "    test_irr_positive_rates.append((returns_test > 0).mean())\n",
    "\n",
    "# ìµœì¢… ê²°ê³¼ ì¶œë ¥\n",
    "best_idx = np.argmax(test_sharpes)\n",
    "print(\"âœ… Best model index:\", best_idx)\n",
    "print(\"âœ… Best validation Sharpe ratio:\", validation_sharpes[best_idx])\n",
    "print(\"âœ… Best test Sharpe ratio:\", test_sharpes[best_idx])\n",
    "print(\"âœ… Best approval rate:\", test_approval_rates[best_idx])\n",
    "print(\"âœ… Mean IRR:\", test_irr_means[best_idx])\n",
    "print(\"âœ… Positive IRR ratio:\", test_irr_positive_rates[best_idx])\n",
    "print(\"âœ… Best threshold:\", best_thresholds[best_idx])\n",
    "print(\"âœ… Best model params:\", best_models[best_idx].get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cfecd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best thresholds from 2 runs:\")\n",
    "print(best_thresholds)\n",
    "\n",
    "print(\"\\nValidation Sharpe Ratios from 2 runs:\")\n",
    "print(validation_sharpes)\n",
    "\n",
    "print(\"\\nTest Sharpe Ratios from 2 runs:\")\n",
    "print(test_sharpes)\n",
    "\n",
    "print(\"\\nTest Approval Rates:\")\n",
    "print(test_approval_rates)\n",
    "\n",
    "print(\"\\nTest IRR Means:\")\n",
    "print(test_irr_means)\n",
    "\n",
    "print(\"\\nTest IRR Positive Rates:\")\n",
    "print(test_irr_positive_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ceb2297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# ìµœì  ëª¨ë¸\n",
    "best_model = best_models[best_idx]\n",
    "\n",
    "# ê²€ì¦ ë°ì´í„°ì—ì„œ ì˜ˆì¸¡ í™•ë¥ \n",
    "y_val_proba = best_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# --------------------------\n",
    "# 1. ROC Curve ì‹œê°í™”\n",
    "# --------------------------\n",
    "fpr, tpr, roc_thresholds = roc_curve(y_val, y_val_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.4f}\", color='blue')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "plt.title(\"âœ… ROC Curve (Validation Set)\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --------------------------\n",
    "# 2. Thresholdë³„ Sharpe Ratio\n",
    "# --------------------------\n",
    "thresholds = np.arange(0.0, 1.0, 0.05)\n",
    "sharpe_ratios = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    approved_mask = y_val_proba <= threshold\n",
    "    denied_mask = ~approved_mask\n",
    "\n",
    "    selected = df_val.copy()\n",
    "    selected.loc[approved_mask, 'irr_adj'] = selected.loc[approved_mask, 'irr']\n",
    "    selected.loc[denied_mask, 'irr_adj'] = selected.loc[denied_mask, 'risk_free_rate']\n",
    "\n",
    "    returns = selected['irr_adj']\n",
    "    risk_free = selected['risk_free_rate']\n",
    "    valid = returns.notnull() & risk_free.notnull()\n",
    "\n",
    "    if valid.sum() < 2:\n",
    "        sharpe_ratios.append(np.nan)\n",
    "    else:\n",
    "        sharpe = calculate_sharpe(returns[valid], risk_free[valid])\n",
    "        sharpe_ratios.append(sharpe)\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.plot(thresholds, sharpe_ratios, marker='o', color='green')\n",
    "plt.title(\"âœ… Sharpe Ratio by Threshold (Validation Set)\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Sharpe Ratio\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c72d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ” IRR í‰ê·  ë° Positive ë¹„ìœ¨ ë¹„êµ\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.scatter(test_approval_rates, test_sharpes, color='purple')\n",
    "plt.title(\"ğŸ¯ Approval Rate vs Sharpe Ratio\")\n",
    "plt.xlabel(\"Approval Rate\")\n",
    "plt.ylabel(\"Test Sharpe Ratio\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
